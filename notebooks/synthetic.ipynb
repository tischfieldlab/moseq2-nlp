{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "415cb8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Optional, List\n",
    "from moseq2_nlp.data import get_transition_representations_n, sample_markov_chain\n",
    "from moseq2_nlp.train import train_regressor, train_svm\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import pdb\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "os.environ['CUDA_DEVICE_ORDER']='PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768bf465",
   "metadata": {},
   "source": [
    "# Synthetic data\n",
    "\n",
    "What are you doing here....?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4276118",
   "metadata": {},
   "source": [
    "## Synthesize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6847e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:03<00:00, 26.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting 1-grams for F_+/+.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                       | 0/27345 [00:00<?, ?it/s]/cs/labs/mornitzan/ricci/projects/moseq2-nlp/moseq2_nlp/data.py:170: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  group_transition_arrays[group][ind] += 1\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27345/27345 [00:00<00:00, 325405.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting 1-grams for F_RH/RH.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 24449/24449 [00:00<00:00, 325834.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting 1-grams for M_+/RH.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 52587/52587 [00:00<00:00, 332343.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting 1-grams for F_+/RH.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49434/49434 [00:00<00:00, 328559.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting 1-grams for M_RH/RH.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 14749/14749 [00:00<00:00, 320006.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting 1-grams for M_+/+.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 22954/22954 [00:00<00:00, 325317.39it/s]\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/cs/labs/mornitzan/ricci/data/abraira'\n",
    "data_name = '2020-11-10_Celsr3_R774H'\n",
    "model_file = os.path.join(data_dir, data_name, 'robust_septrans_model_1000.p')\n",
    "index_file = os.path.join(data_dir, data_name, 'gender-genotype-index.yaml')\n",
    "\n",
    "# Get nth order transitions (usages, transitions, 3grams, etc.)\n",
    "n=1\n",
    "group_transition_arrays = get_transition_representations_n(model_file, index_file, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "233f6640",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthesizing F_+/+.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                          | 0/25 [00:00<?, ?it/s]/cs/labs/mornitzan/ricci/projects/moseq2-nlp/moseq2_nlp/data.py:197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  probs = np.squeeze(tmx[ind])\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:03<00:00,  6.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthesizing F_RH/RH.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:03<00:00,  6.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthesizing M_+/RH.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:03<00:00,  6.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthesizing F_+/RH.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:03<00:00,  6.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthesizing M_RH/RH.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:03<00:00,  6.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthesizing M_+/+.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:03<00:00,  6.63it/s]\n"
     ]
    }
   ],
   "source": [
    "num_animals_per_group = 25\n",
    "num_syllables_range = [10000,15000]\n",
    "all_synthesized_data = []\n",
    "labels = []\n",
    "\n",
    "for l, (group, tmx) in enumerate(group_transition_arrays.items()):\n",
    "    print(f'Synthesizing {group}.')\n",
    "    for _ in tqdm(range(num_animals_per_group)):\n",
    "        num_syllables = np.random.randint(num_syllables_range[0], num_syllables_range[1])\n",
    "        all_synthesized_data.append(sample_markov_chain(tmx,num_syllables))\n",
    "        labels.append(l)\n",
    "        \n",
    "documents = [TaggedDocument(sent, [i]) for i, sent in enumerate(all_synthesized_data)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed867e8d",
   "metadata": {},
   "source": [
    "## Train on synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d06d0c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dm=1\n",
      "Training dm=0\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "dim = 300 #max_syllable # Dimension of embedding space\n",
    "window = 1 # Window size for context (this is left and right, so total size is 2*window)\n",
    "\n",
    "# Initialize and train two models on the documents. Embeddings will be averaged, which is standard. \n",
    "# Note: min_count = <min_count> omits words with usages less than <min_count>\n",
    "print('Training dm=1')\n",
    "model1 = Doc2Vec(documents, dm=1, epochs=50, vector_size=dim, window=window, min_count=1, workers=1)\n",
    "print('Training dm=0')\n",
    "model2 = Doc2Vec(documents, dm=0, epochs=50, vector_size=dim, window=window, min_count=1, workers=1)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34694992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infer embeddings per document per model and then average. \n",
    "E1 = [model1.infer_vector(sent) for sent in all_synthesized_data]\n",
    "E2 = [model2.infer_vector(sent) for sent in all_synthesized_data]\n",
    "E = [.5 * (em1 + em2) for (em1, em2) in zip(E1, E2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501f2591",
   "metadata": {},
   "source": [
    "## Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72a21118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier\n",
      "0.1 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier = 'logistic_regression'\n",
    "scoring = 'accuracy'\n",
    "K = 1\n",
    "penalty = 'l2'\n",
    "num_c = 11\n",
    "seed = 0\n",
    "\n",
    "print('Training classifier')\n",
    "if classifier == 'logistic_regression':\n",
    "    best_C, best_score = train_regressor(E, labels, K, scoring, penalty, num_c, seed)\n",
    "elif classifier == 'svm':\n",
    "    best_C, best_score = train_svm(E, labels, kernel, K, scoring, penalty, num_c, seed)\n",
    "    \n",
    "print(best_C, best_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
